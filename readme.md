This is a spider & data cleaning streamlined solution.

If you appreciate my hard work, please show your support by leaving a star
If you encounter any issues, please feel free to contact me with any questions or concerns.


If you want to use my scripts, you MUST EDIT YOUR OWN STEP #1.

It contains 3 steps:
- Step 1: fetch(crawl) image links and drop the duplicates.
- Step 2: download images by multiprocessing (multithreading is a fake idea to Python scripts)
- Step 3: clean the images
  - eliminate duplicates by md5
  - calculate the image hash
  - calculate the similarity by the image hash
  - discard the smaller similar images.


Thank you for choosing my program and I hope you enjoy this time-saving and enjoyable experience.
